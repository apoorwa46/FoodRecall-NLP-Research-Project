{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCHnX3UDlOxPcKv/OlWkry",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apoorwa46/FoodRecall-NLP-Research-Project/blob/main/Food_Recall_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvZg6kPUsjQr",
        "outputId": "179393c0-3f65-4279-8eb6-f9bc149694c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training Data: (3172, 9)\n",
            "Validation Data: (357, 9)\n",
            "Unseen Data: (1005, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8457 - loss: 0.6443 - val_accuracy: 0.9524 - val_loss: 0.1513\n",
            "Epoch 2/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9644 - loss: 0.1143 - val_accuracy: 0.9356 - val_loss: 0.1451\n",
            "Epoch 3/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9825 - loss: 0.0537 - val_accuracy: 0.9440 - val_loss: 0.1434\n",
            "Epoch 4/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9966 - loss: 0.0238 - val_accuracy: 0.9356 - val_loss: 0.1386\n",
            "Epoch 5/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0096 - val_accuracy: 0.9468 - val_loss: 0.1432\n",
            "Epoch 6/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0041 - val_accuracy: 0.9468 - val_loss: 0.1566\n",
            "Epoch 7/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9986 - loss: 0.0034 - val_accuracy: 0.9468 - val_loss: 0.1533\n",
            "Epoch 8/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.9384 - val_loss: 0.1810\n",
            "Epoch 9/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9990 - loss: 0.0024 - val_accuracy: 0.9468 - val_loss: 0.1752\n",
            "Epoch 10/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9985 - loss: 0.0040 - val_accuracy: 0.9440 - val_loss: 0.1759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Validation Accuracy: 0.9439775910364145\n",
            "Classification Report:\n",
            "                             precision    recall  f1-score   support\n",
            "\n",
            "               Food Recall       0.97      0.95      0.96       176\n",
            "Foodborne Disease Outbreak       0.93      0.96      0.94       176\n",
            "                   Neither       0.00      0.00      0.00         5\n",
            "\n",
            "                  accuracy                           0.94       357\n",
            "                 macro avg       0.63      0.64      0.63       357\n",
            "              weighted avg       0.93      0.94      0.94       357\n",
            "\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "   docid                                               text  \\\n",
            "0     49  The previously reported outbreak of Salmonella...   \n",
            "1   5147  Two California women are suing Don Antonio's, ...   \n",
            "2   5002  Oct. 28 update: As of Tuesday night, Oct. 27, ...   \n",
            "3   1603  Canadian food safety officials are investigati...   \n",
            "4   4233  Chipotle Mexican Grill's stock is dropping lik...   \n",
            "\n",
            "              Predicted_Label  \n",
            "0  Foodborne Disease Outbreak  \n",
            "1  Foodborne Disease Outbreak  \n",
            "2  Foodborne Disease Outbreak  \n",
            "3                 Food Recall  \n",
            "4  Foodborne Disease Outbreak  \n",
            "Predictions saved to Drive ✅\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ==============================\n",
        "# STEP 0: Setup\n",
        "# ==============================\n",
        "!pip install pandas scikit-learn tensorflow openpyxl joblib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import joblib\n",
        "\n",
        "# ==============================\n",
        "# STEP 1: Mount Google Drive\n",
        "# ==============================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ==============================\n",
        "# STEP 2: Load Excel Files\n",
        "# ==============================\n",
        "train_file = \"/content/drive/MyDrive/FoodRecall/file1.xlsx\"\n",
        "val_file   = \"/content/drive/MyDrive/FoodRecall/file2.xlsx\"\n",
        "unseen_file = \"/content/drive/MyDrive/FoodRecall/file3.xlsx\"\n",
        "\n",
        "df_train = pd.read_excel(train_file)\n",
        "df_val = pd.read_excel(val_file)\n",
        "df_unseen = pd.read_excel(unseen_file)\n",
        "\n",
        "# Drop first row (duplicate headers inside the file)\n",
        "df_train = df_train.drop(0).reset_index(drop=True)\n",
        "df_val = df_val.drop(0).reset_index(drop=True)\n",
        "\n",
        "print(\"Training Data:\", df_train.shape)\n",
        "print(\"Validation Data:\", df_val.shape)\n",
        "print(\"Unseen Data:\", df_unseen.shape)\n",
        "\n",
        "# ==============================\n",
        "# STEP 3: Preprocess Data\n",
        "# ==============================\n",
        "target_col = \"Task1_Label\"\n",
        "text_col = \"Unnamed: 1\"   # This is the text column\n",
        "\n",
        "# Features and target\n",
        "X_train_text = df_train[text_col].astype(str)\n",
        "y_train = df_train[target_col]\n",
        "\n",
        "X_val_text = df_val[text_col].astype(str)\n",
        "y_val = df_val[target_col]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_val = label_encoder.transform(y_val)\n",
        "\n",
        "# Convert text → TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train = vectorizer.fit_transform(X_train_text)\n",
        "X_val = vectorizer.transform(X_val_text)\n",
        "\n",
        "# Save encoder + vectorizer\n",
        "joblib.dump(label_encoder, \"/content/drive/MyDrive/FoodRecall/label_encoder.pkl\")\n",
        "joblib.dump(vectorizer, \"/content/drive/MyDrive/FoodRecall/tfidf_vectorizer.pkl\")\n",
        "\n",
        "# ==============================\n",
        "# STEP 4: Build Model\n",
        "# ==============================\n",
        "model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(len(np.unique(y_train)), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# ==============================\n",
        "# STEP 5: Train Model\n",
        "# ==============================\n",
        "history = model.fit(\n",
        "    X_train.toarray(), y_train,\n",
        "    validation_data=(X_val.toarray(), y_val),\n",
        "    epochs=10,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Save model\n",
        "model.save(\"/content/drive/MyDrive/FoodRecall/food_model.h5\")\n",
        "\n",
        "# ==============================\n",
        "# STEP 6: Evaluate Model\n",
        "# ==============================\n",
        "val_pred = model.predict(X_val.toarray())\n",
        "val_pred_labels = np.argmax(val_pred, axis=1)\n",
        "\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, val_pred_labels))\n",
        "print(\"Classification Report:\\n\", classification_report(y_val, val_pred_labels, target_names=label_encoder.classes_))\n",
        "\n",
        "# ==============================\n",
        "# STEP 7: Use Model on Unseen Data\n",
        "# ==============================\n",
        "# Use the same text column\n",
        "X_unseen_text = df_unseen[\"text\"].astype(str) if \"text\" in df_unseen.columns else df_unseen[text_col].astype(str)\n",
        "\n",
        "# Apply same vectorizer\n",
        "X_unseen = vectorizer.transform(X_unseen_text)\n",
        "\n",
        "# Predict\n",
        "unseen_pred = model.predict(X_unseen.toarray())\n",
        "unseen_labels = label_encoder.inverse_transform(np.argmax(unseen_pred, axis=1))\n",
        "\n",
        "# Attach predictions\n",
        "df_unseen[\"Predicted_Label\"] = unseen_labels\n",
        "print(df_unseen.head())\n",
        "\n",
        "# Save results\n",
        "df_unseen.to_excel(\"/content/drive/MyDrive/FoodRecall/unseen_predictions.xlsx\", index=False)\n",
        "print(\"Predictions saved to Drive ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STEP 0: Setup\n",
        "# ==============================\n",
        "!pip install pandas scikit-learn openpyxl joblib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "\n",
        "# ==============================\n",
        "# STEP 1: Mount Google Drive\n",
        "# ==============================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ==============================\n",
        "# STEP 2: Load Excel Files\n",
        "# ==============================\n",
        "train_file = \"/content/drive/MyDrive/FoodRecall/file1.xlsx\"\n",
        "val_file   = \"/content/drive/MyDrive/FoodRecall/file2.xlsx\"\n",
        "unseen_file = \"/content/drive/MyDrive/FoodRecall/file3.xlsx\"\n",
        "\n",
        "df_train = pd.read_excel(train_file)\n",
        "df_val = pd.read_excel(val_file)\n",
        "df_unseen = pd.read_excel(unseen_file)\n",
        "\n",
        "# Drop first row if it's a duplicate header\n",
        "df_train = df_train.drop(0).reset_index(drop=True)\n",
        "df_val = df_val.drop(0).reset_index(drop=True)\n",
        "\n",
        "print(\"Training Data:\", df_train.shape)\n",
        "print(\"Validation Data:\", df_val.shape)\n",
        "print(\"Unseen Data:\", df_unseen.shape)\n",
        "\n",
        "# ==============================\n",
        "# STEP 3: Preprocess Data\n",
        "# ==============================\n",
        "target_col = \"Task1_Label\"\n",
        "text_col = \"Unnamed: 1\"   # The text column\n",
        "\n",
        "# Features and target\n",
        "X_train_text = df_train[text_col].astype(str)\n",
        "y_train = df_train[target_col]\n",
        "\n",
        "X_val_text = df_val[text_col].astype(str)\n",
        "y_val = df_val[target_col]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_val = label_encoder.transform(y_val)\n",
        "\n",
        "# Convert text → TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train = vectorizer.fit_transform(X_train_text)\n",
        "X_val = vectorizer.transform(X_val_text)\n",
        "\n",
        "# Save encoder + vectorizer\n",
        "joblib.dump(label_encoder, \"/content/drive/MyDrive/FoodRecall/label_encoder.pkl\")\n",
        "joblib.dump(vectorizer, \"/content/drive/MyDrive/FoodRecall/tfidf_vectorizer.pkl\")\n",
        "\n",
        "# ==============================\n",
        "# METHOD 1: Logistic Regression\n",
        "# ==============================\n",
        "print(\"\\n=== Training Logistic Regression Model ===\")\n",
        "\n",
        "# Train model\n",
        "log_reg = LogisticRegression(max_iter=200)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred_val = log_reg.predict(X_val)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred_val))\n",
        "print(\"Classification Report:\\n\", classification_report(y_val, y_pred_val, target_names=label_encoder.classes_))\n",
        "\n",
        "# Save model\n",
        "joblib.dump(log_reg, \"/content/drive/MyDrive/FoodRecall/logistic_model.pkl\")\n",
        "\n",
        "# ==============================\n",
        "# STEP 4: Predict on Unseen Data\n",
        "# ==============================\n",
        "# Use the same text column as before\n",
        "X_unseen_text = df_unseen[\"text\"].astype(str) if \"text\" in df_unseen.columns else df_unseen[text_col].astype(str)\n",
        "\n",
        "# Transform using same vectorizer\n",
        "X_unseen = vectorizer.transform(X_unseen_text)\n",
        "\n",
        "# Predict\n",
        "unseen_pred = log_reg.predict(X_unseen)\n",
        "df_unseen[\"Predicted_Label_LogReg\"] = label_encoder.inverse_transform(unseen_pred)\n",
        "\n",
        "# Save results\n",
        "df_unseen.to_excel(\"/content/drive/MyDrive/FoodRecall/unseen_predictions_logreg.xlsx\", index=False)\n",
        "print(\"✅ Logistic Regression predictions saved successfully!\")\n",
        "\n",
        "# Optional: show sample predictions\n",
        "print(\"\\nSample predictions:\")\n",
        "print(df_unseen[[\"Predicted_Label_LogReg\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzYoE7BmGwxQ",
        "outputId": "d85e5410-9a47-4fe6-9c07-a3a153a862d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Mounted at /content/drive\n",
            "Training Data: (3172, 9)\n",
            "Validation Data: (357, 9)\n",
            "Unseen Data: (1005, 2)\n",
            "\n",
            "=== Training Logistic Regression Model ===\n",
            "Validation Accuracy: 0.9523809523809523\n",
            "Classification Report:\n",
            "                             precision    recall  f1-score   support\n",
            "\n",
            "               Food Recall       0.98      0.95      0.97       176\n",
            "Foodborne Disease Outbreak       0.93      0.98      0.95       176\n",
            "                   Neither       0.00      0.00      0.00         5\n",
            "\n",
            "                  accuracy                           0.95       357\n",
            "                 macro avg       0.64      0.64      0.64       357\n",
            "              weighted avg       0.94      0.95      0.95       357\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logistic Regression predictions saved successfully!\n",
            "\n",
            "Sample predictions:\n",
            "       Predicted_Label_LogReg\n",
            "0  Foodborne Disease Outbreak\n",
            "1  Foodborne Disease Outbreak\n",
            "2  Foodborne Disease Outbreak\n",
            "3                 Food Recall\n",
            "4  Foodborne Disease Outbreak\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STEP 0: Setup\n",
        "# ==============================\n",
        "!pip install pandas scikit-learn tensorflow openpyxl joblib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "# ==============================\n",
        "# STEP 1: Mount Google Drive\n",
        "# ==============================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ==============================\n",
        "# STEP 2: Load Excel Files\n",
        "# ==============================\n",
        "train_file = \"/content/drive/MyDrive/FoodRecall/file1.xlsx\"\n",
        "val_file   = \"/content/drive/MyDrive/FoodRecall/file2.xlsx\"\n",
        "unseen_file = \"/content/drive/MyDrive/FoodRecall/file3.xlsx\"\n",
        "\n",
        "df_train = pd.read_excel(train_file)\n",
        "df_val = pd.read_excel(val_file)\n",
        "df_unseen = pd.read_excel(unseen_file)\n",
        "\n",
        "# Drop first row if duplicate header\n",
        "df_train = df_train.drop(0).reset_index(drop=True)\n",
        "df_val = df_val.drop(0).reset_index(drop=True)\n",
        "\n",
        "print(\"Training Data:\", df_train.shape)\n",
        "print(\"Validation Data:\", df_val.shape)\n",
        "print(\"Unseen Data:\", df_unseen.shape)\n",
        "\n",
        "# ==============================\n",
        "# STEP 3: Preprocess Data\n",
        "# ==============================\n",
        "target_col = \"Task1_Label\"\n",
        "text_col = \"Unnamed: 1\"   # Text column name\n",
        "\n",
        "# Features and target\n",
        "X_train_text = df_train[text_col].astype(str)\n",
        "y_train = df_train[target_col]\n",
        "\n",
        "X_val_text = df_val[text_col].astype(str)\n",
        "y_val = df_val[target_col]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_val = label_encoder.transform(y_val)\n",
        "\n",
        "# Save encoder for reuse\n",
        "joblib.dump(label_encoder, \"/content/drive/MyDrive/FoodRecall/label_encoder.pkl\")\n",
        "\n",
        "# ==============================\n",
        "# METHOD 2: LSTM Deep Learning\n",
        "# ==============================\n",
        "print(\"\\n=== Training LSTM Deep Learning Model ===\")\n",
        "\n",
        "# Tokenize text\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train_text)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val_text)\n",
        "\n",
        "# Handle unseen data text column safely\n",
        "if \"text\" in df_unseen.columns:\n",
        "    X_unseen_text = df_unseen[\"text\"].astype(str)\n",
        "else:\n",
        "    X_unseen_text = df_unseen[text_col].astype(str)\n",
        "\n",
        "X_unseen_seq = tokenizer.texts_to_sequences(X_unseen_text)\n",
        "\n",
        "# Pad sequences (same length)\n",
        "max_len = 100\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
        "X_val_pad = pad_sequences(X_val_seq, maxlen=max_len, padding='post')\n",
        "X_unseen_pad = pad_sequences(X_unseen_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "# Build model\n",
        "lstm_model = Sequential([\n",
        "    Embedding(input_dim=10000, output_dim=64, input_length=max_len),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(len(np.unique(y_train)), activation='softmax')\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = lstm_model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=5,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "val_pred = lstm_model.predict(X_val_pad)\n",
        "val_labels = np.argmax(val_pred, axis=1)\n",
        "\n",
        "print(\"\\nValidation Accuracy:\", accuracy_score(y_val, val_labels))\n",
        "print(\"Classification Report:\\n\", classification_report(y_val, val_labels, target_names=label_encoder.classes_))\n",
        "\n",
        "# Save model and tokenizer\n",
        "lstm_model.save(\"/content/drive/MyDrive/FoodRecall/lstm_food_model.h5\")\n",
        "joblib.dump(tokenizer, \"/content/drive/MyDrive/FoodRecall/tokenizer.pkl\")\n",
        "\n",
        "# ==============================\n",
        "# STEP 4: Predict on Unseen Data\n",
        "# ==============================\n",
        "unseen_pred = lstm_model.predict(X_unseen_pad)\n",
        "unseen_labels = label_encoder.inverse_transform(np.argmax(unseen_pred, axis=1))\n",
        "\n",
        "df_unseen[\"Predicted_Label_LSTM\"] = unseen_labels\n",
        "\n",
        "# Save results\n",
        "df_unseen.to_excel(\"/content/drive/MyDrive/FoodRecall/unseen_predictions_lstm.xlsx\", index=False)\n",
        "print(\"✅ LSTM model predictions saved successfully!\")\n",
        "\n",
        "# Optional: show sample predictions\n",
        "print(\"\\nSample predictions:\")\n",
        "print(df_unseen[[\"Predicted_Label_LSTM\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdN5VSJ9IL8P",
        "outputId": "b51ef930-5e56-4267-b2e4-64c8c64c64cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training Data: (3172, 9)\n",
            "Validation Data: (357, 9)\n",
            "Unseen Data: (1005, 2)\n",
            "\n",
            "=== Training LSTM Deep Learning Model ===\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.4693 - loss: 0.9013 - val_accuracy: 0.5574 - val_loss: 0.7553\n",
            "Epoch 2/5\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.5125 - loss: 0.7596 - val_accuracy: 0.7143 - val_loss: 0.6886\n",
            "Epoch 3/5\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.7828 - loss: 0.5886 - val_accuracy: 0.8711 - val_loss: 0.3835\n",
            "Epoch 4/5\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - accuracy: 0.8889 - loss: 0.3530 - val_accuracy: 0.8627 - val_loss: 0.3701\n",
            "Epoch 5/5\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.8985 - loss: 0.3321 - val_accuracy: 0.8627 - val_loss: 0.3835\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation Accuracy: 0.8627450980392157\n",
            "Classification Report:\n",
            "                             precision    recall  f1-score   support\n",
            "\n",
            "               Food Recall       0.96      0.78      0.86       176\n",
            "Foodborne Disease Outbreak       0.80      0.97      0.87       176\n",
            "                   Neither       0.00      0.00      0.00         5\n",
            "\n",
            "                  accuracy                           0.86       357\n",
            "                 macro avg       0.59      0.58      0.58       357\n",
            "              weighted avg       0.87      0.86      0.86       357\n",
            "\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
            "✅ LSTM model predictions saved successfully!\n",
            "\n",
            "Sample predictions:\n",
            "         Predicted_Label_LSTM\n",
            "0  Foodborne Disease Outbreak\n",
            "1  Foodborne Disease Outbreak\n",
            "2  Foodborne Disease Outbreak\n",
            "3                 Food Recall\n",
            "4  Foodborne Disease Outbreak\n"
          ]
        }
      ]
    }
  ]
}